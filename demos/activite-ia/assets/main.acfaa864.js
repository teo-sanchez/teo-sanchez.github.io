async function se(e={},t){const{width:n,height:s,min:i,max:r,bw:a}=E(E({},We),e),o=G(()=>{let e=F(t);if(n>0&&s>0)e=L.resizeBilinear(e,[n,s]);else if(n>0&&0===s){const s=t.height*n/t.width;e=L.resizeBilinear(e,[n,s])}else if(0===n&&s>0){const n=t.width*s/t.height;e=L.resizeBilinear(e,[n,s])}if(a){const t=N(.2989),n=N(.587),s=N(.114),i=z(e,[0,0,0],[e.shape[0],e.shape[1],1]),r=z(e,[0,0,1],[e.shape[0],e.shape[1],1]),a=z(e,[0,0,2],[e.shape[0],e.shape[1],1]);e=$e(Q(Q(i.mul(t),r.mul(n)),a.mul(s)),[2])}return e=Te(e,(r-i)/255),e=De(e,i)}),l=await o.array();return o.dispose(),l}function He(e={},t){return void 0!==t?se(e,t):t=>se(e,t)}function b(e,t,n,s){return`<iframe src='${e}?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479' \n        width='${n}' height='${s}' \n        frameborder='0' allow='autoplay; fullscreen; picture-in-picture' allowfullscreen \n        title='${t}'></iframe>`}async function ht(e){const t=new Image;return new Promise(n=>{t.addEventListener("load",async()=>{const e=G(()=>{const e=Fe(F(t),N(255));return[L.resizeBilinear(e,[k,k]),L.resizeBilinear(e,[80,80])]}),s=new ImageData(await te(e[0]),k,k),i=document.createElement("canvas");await te(e[1],i);const r=i.toDataURL("image/jpeg");e[0].dispose(),e[1].dispose(),n([s,r])}),t.src=e})}async function C(e,t){"train"==t?await c.clear():await m.clear();const n=Array.from(Array(10),(n,s)=>[`https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/data/${e}/${t}/correct_${t}_${s+1}.jpeg`,"correct"]),s=Array.from(Array(10),(n,s)=>[`https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/data/${e}/${t}/incorrect_${t}_${s+1}.jpeg`,"incorrect"]),i=Array.from(Array(10),(n,s)=>[`https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/data/${e}/${t}/absent_${t}_${s+1}.jpeg`,"absent"]);let r=Promise.resolve();n.concat(s).concat(i).forEach(([e,n])=>{r=r.then(async()=>{const[s,i]=await ht(e),r={type:"image",image:s,y:n,thumbnail:i,x:await S.process(s),raw_features:await He({width:8,height:8,max:1,bw:!0},s)};"train"==t?await c.create(r):await m.create(r)})}),await r}function Nt(e){var t=new Uint8ClampedArray(e.width*e.height*4);for(let n=0;n<=3;n++)for(let s=0;s<e.width;s++)for(let i=0;i<e.height;i++)t[s*e.width*4+4*i+n]=e.data[s*e.width*4+4*(e.width-i)+n];return new ImageData(t,e.width,e.height)}var Ae=Object.defineProperty,K=Object.getOwnPropertySymbols,Ie=Object.prototype.hasOwnProperty,je=Object.prototype.propertyIsEnumerable,J=(e,t,n)=>t in e?Ae(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,E=(e,t)=>{for(var n in t||(t={}))Ie.call(t,n)&&J(e,n,t[n]);if(K)for(var n of K(t))je.call(t,n)&&J(e,n,t[n]);return e};import{t as G,f as F,i as L,s as N,a as z,b as $e,c as Q,m as Te,d as De,e as l,w as Be,g as q,h as Re,j as W,k as H,l as Ue,n as Oe,o as Y,p as Z,q as Ve,r as Ke,u as _,v as M,x as X,y as Je,z as ee,A as Ge,B as Fe,C as te}from"./vendor.e33fb0e0.js";const Qe=function(){function e(e){const t={};return e.integrity&&(t.integrity=e.integrity),e.referrerpolicy&&(t.referrerPolicy=e.referrerpolicy),"use-credentials"===e.crossorigin?t.credentials="include":"anonymous"===e.crossorigin?t.credentials="omit":t.credentials="same-origin",t}function t(t){if(t.ep)return;t.ep=!0;const n=e(t);fetch(t.href,n)}const n=document.createElement("link").relList;if(!(n&&n.supports&&n.supports("modulepreload"))){for(const e of document.querySelectorAll('link[rel="modulepreload"]'))t(e);new MutationObserver(e=>{for(const n of e)if("childList"===n.type)for(const e of n.addedNodes)"LINK"===e.tagName&&"modulepreload"===e.rel&&t(e)}).observe(document,{childList:!0,subtree:!0})}};Qe();const We={width:0,height:0,min:0,max:255,bw:!1},Ye={author:{name:"T\xe9o Sanchez"},dashboards:{title:"TP: apprentissage automatique"}},Ze={name:"Introduction",text:{title:"",content:"Voir dans le fichier index.js"},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},Xe={name:"Histoire",text:{title:"",content:"Voir dans le fichier index.js"},timeline:"Chronologie de l'intelligence artificielle",video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},et={name:"Donn\xe9es",text:{title:"",content:"Voir dans le fichier index.js"},webcam:"Cam\xe9ra",input_files:"Charger des images",label:"Aposer une \xe9tiquette",button:"Enregistrer des images \xe9tiquet\xe9es de la cam\xe9ra",message_button:"Maintenir pour capturer",browser:{train:"Donn\xe9es d'entra\xeenement",test:"Donn\xe9es de test"},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},tt={name:"Attributs",text:{title:"",content:"Voir dans le fichier index.js"},feature_title:"Les 1024 attributs calcul\xe9s par le r\xe9seau de neurone pr\xe9-entra\xeen\xe9 MobileNetV1",title:"Extracteur d'attributs",video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},st={name:"Entra\xeenement",text:{title:"",content:"Voir dans le fichier index.js"},knn:{text:{title:"",content:"Voir dans le fichier index.js"},progress:"Progression de l'entra\xeenement",params:"Param\xe8tres du classifieur kNN"},mlp:{text:{title:"",content:"Voir dans le fichier index.js"},progress:"Progression de l'entra\xeenement",params:"Couches cach\xe9es du perceptron",plot:"Courbe d'apprentissage"},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},nt={name:"\xc9valuation",text:{title:"",content:"Voir dans le fichier index.js"},knn:{button:{title:"",content:"Mettre \xe0 jour les r\xe9sulats du kNN"},matrix:{train:"Matrice de corr\xe9lation du kNN sur l'ensemble d'entra\xeenement",test:"Matrice de corr\xe9lation du kNN sur l'ensemble de test"}},mlp:{button:{title:"",content:"Mettre \xe0 jour les r\xe9sulats du MLP"},matrix:{train:"Matrice de corr\xe9lation du MLP sur l'ensemble d'entra\xeenement",test:"Matrice de corr\xe9lation du MLP sur l'ensemble de test"}},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},it={name:"D\xe9ploiement",text:{title:"",content:"Voir dans le fichier index.js"},display:"Image s\xe9lectionn\xe9e",toggle:{title:"Utiliser",content:"Activer"},mlp:{plot:"Pr\xe9dictions du MLP"},knn:{plot:"Pr\xe9dictions du kNN"},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},rt={name:"Attaque adversaire",text:{title:"",content:"Voir dans le fichier index.js"},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}},at={name:"Cr\xe9dits",text:{title:"",content:"Voir dans le fichier index.js"}},ot={name:"Aider la recherche!",text:{title:"",content:"Voir dans le fichier index.js"},video:{url:"https://www.youtube.com/embed/JMS8WUEnxdQ",width:300,height:300,title:"Explications vid\xe9o"}};var e={misc:Ye,introduction:Ze,history:Xe,data:et,embedding:tt,training:st,evaluation:nt,deployment:it,adversarial:rt,credits:at,research:ot};const k=224,lt=l(b(e.introduction.video.url,e.introduction.video.title,e.introduction.video.width,e.introduction.video.height));lt.title=e.introduction.video.title;const ne=l("\n<h4>Bienvenue dans ce premier TP sur l'intelligence artificielle et l'apprentissage machine.</h4>\nDans ce TP, vous allez d\xe9couvrir plusieurs aspects de l'intelligence artificielle (IA): <BR>\n<ul>\n  <li> Nous d\xe9couvrirons d'abord son histoire r\xe9cente et mouvement\xe9e, des ann\xe9es 1940 jusqu'\xe0 nos jours. Le d\xe9velopement de l'IA a toujours suscit\xe9 beaucoup de promesses et de fantasmes. Au travers de cette histoire, nous essayerons de comprendre quels ont \xe9t\xe9 les accomplissements de l'IA. </li>\n  <li> Dans un second temps, nous explorerons un domaine tr\xe8s repr\xe9sent\xe9 de l'intelligence artificielle: l'<b>apprentissage automatique</b> (Machine Learning en anglais). Pour cela, vous ferez apprendre un algorithme \xe0 cat\xe9goriser des images.\n  Vous aurez le choix entre deux bases de donn\xe9es associ\xe9es aux th\xe9matiques de <b>la reconnaissance faciale</b> et de <b>la conduite autonome</b>. \n  <li> Enfin, nous vous invitons \xe0 participer \xe0 <b>une \xe9tude de recherche sociologique</b> en r\xe9pondant \xe0 questionnaire annonyme.\n  Vos r\xe9ponses aideront la recherche publique \xe0 mieux comprendre ce que vous avez appris au travers de ce TP et ce que vous pensez de l'IA.\n  </li>\n</ul>\n<BR>\n\nLe TP est divis\xe9 en plusieurs activit\xe9s, accessibles gr\xe2ce aux diff\xe9rents onglets visibles en haut de le page.\nDes consignes \xe9crite et vid\xe9o expliquant le d\xe9roul\xe9 de l'activit\xe9 sera disponible dans chaque page.\nVous aurez \xe9galement acc\xe8s \xe0 des outils interactifs pour entra\xeener des algorithmes d'apprentissage machine.\nLes questions associ\xe9es \xe0 ce TP sont disponibles <a href=\"https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/ennonce_TP_IA.pdf\" target=\"_blank\">\xe0 cette addresse</a>, ou sera distribu\xe9 par votre enseignant.\n<BR>\n<BR>\nIl ne vous reste plus  qu'\xe0 commencer la premi\xe8re activit\xe9 sur l'histoire de l'intelligence artificielle en cliquant sur l'activit\xe9 \"Histoire\". <br><br>\nBon travail !\n");ne.title=e.introduction.text.title;const ut=l(b(e.history.video.url,e.history.video.title,e.history.video.width,e.history.video.height));ut.title=e.history.video.title;const ie=l("\n<h4> Avant d'entrer dans la pratique, nous allons d\xe9couvrir l'histoire du d\xe9velopement de l'intelligence artificielle (IA).</h4>\nCette histoire scientifique est marqu\xe9e par des changements de <b>paradigmes</b> c'est \xe0 dire de mani\xe8re de voir les choses.<BR>\nLes deux grands paradigmes de l'IA qui se sont succ\xe9d\xe9s peuvent \xeatre regroup\xe9s en deux familles: l'approche <b>connexioniste</b> et l'approche <b>symbolique</b>.\nCes deux approches ont des points de vues diff\xe9rents sur la fa\xe7on dont l'esprit humain fonctionne et devrait \xeatre simul\xe9 avec des algorithmes:\n<ul>\n<li> L'approche <b>connexioniste</b> pense que la cognition humaine (ou animale) \xe9merge de l'interconnexion entre les neurones lorsqu'ils sont organis\xe9s en r\xe9seau.\nPour simuler des comportements cognitifs intelligents, les chercheurs connexionnistes cherchent \xe0 comprendre et mod\xe9liser les neurones biologiques et de simuler leurs comportements dans des machines.\n<li> L'approche <b>symbolique</b> consid\xe8re que l'esprit n'acc\xe8de pas directement au monde mais par l'interm\xe9diaires de repr\xe9sentations.\nPour cette \xe9cole de pens\xe9e, l'enjeux est de trouver les repr\xe9sentations appropri\xe9s de l'esprit humain, et d'introduire explicitement ces repr\xe9sentations (ou symboles) dans les ordinateurs afin de pouvoir y conduire des raisonnements.\n</ul>\n\nC'est par l'approche connexionniste que le domaine de recherche a d\xe9but\xe9 entre les ann\xe9es  40 et 60, avant m\xeame queles ordinateurs n'existent.\nLe chercheur <b>Frank Rosenblatt construit alors le Perceptron</b>, un r\xe9seau de neurone artificiel simul\xe9 avec des circuits \xe9lectriques analogiques.\n<br><br>\nL'approche symbolique critiquera le manque de rigueur math\xe9matique des travaux de Rosenblatt.\nCette approche d\xe9bute en 1956 avec <b>la conf\xe9rence de Darmouth</b>.\nElle est men\xe9 par une poign\xe9e de chercheurs am\xe9ricains: les math\xe9maticiens Marvin Minsky et John McCarthy et les psychologues Allen Newell et Herbert Simon.\nC'est lors de cette conf\xe9rence que sera choisi le terme intelligence artificielle pour d\xe9signer le domaine.\nCe terme, un peu pr\xe9somptueux et regroupant des disciplines diverses, sera souvent accompagn\xe9 de pr\xe9dictions irr\xe9alistes de la part des m\xe9dias mais aussi des chercheurs!\nCes pr\xe9visions attireront les investissements, venant surtout des corps de l'arm\xe9e am\xe9ricaine. Ces derniers esp\xe8rent des avanc\xe9es strat\xe9giques pour gagner la guerre froide: la traduction automatique du russe ou des armes contr\xf4l\xe9s \xe0 distance, par commandes vocales.\nBien loin de cela, les applications de l'IA symbolique se limitaient \xe0 des probl\xe8mes simples, o\xf9 l'on peut facilement y projetter des r\xe8gles de logique: la g\xe9om\xe9trie ou des jeux de plateaux commes les \xe9checs ou les dames.\nCes d\xe9convenues provoqueront l'arr\xeat des financements \xe0 deux reprises et sur de longues p\xe9riodes (environ 10 ans). On parle d'<b>hivers de l'intelligence artificiel</b>.\n<br><br>\nL'approche connexioniste a finalement repris le dessus dans les ann\xe9es 2000 et 2010 lorsque les performances des r\xe9seaux de neurones artificiels ont bondi.\nDe nos jour, un r\xe9seau de neurone apprends \xe0 r\xe9aliser une t\xe2che (classification, r\xe9gression ou g\xe9n\xe9ration) en apprenant sur de grandes bases de donn\xe9es brutes (de l'image, de l'audio, du texte).\nLes neurones artificiels sont organis\xe9s en couches interconnect\xe9s, sur plusieurs niveaux de profondeur: on parle d'apprentissage profond ou Deep Learning.\nSimuler de tels architectures n\xe9cessite des calculs parall\xe8les avec des cartes graphiques (GPU), les m\xeames utilis\xe9s par les gamers.\nLes chercheurs pionniers du domaines sont le fran\xe7ais Yann Lecun et les canadiens Joshua Bengio et Geoffrey Hinton.\nLeur approche a bouscul\xe9 de nombreux domaines o\xf9 les scientifiques tentaient de mod\xe9liser explicitement des ph\xe9nom\xe8nes.\nAvec le Deep Learning, ces ph\xe9nom\xe8nes peuvent \xeatre mod\xe9lis\xe9s si l'on dispose de la bonne architecture, des bons param\xe8tres, de suffisemment de donn\xe9es et de puissance de calcul.\nUne fois le ph\xe9nom\xe8ne mod\xe9lis\xe9, on peut r\xe9aliser des <b>pr\xe9dictions</b> sur des donn\xe9es nouvelles.\n<br><br>\nDe nos jours, les algorithmes d'apprentissage machine d\xe9ploy\xe9s \xe0 grande \xe9chelle sur internet, les r\xe9seaux sociaux et dans les institutions.\nLes entreprises priv\xe9es d\xe9tiennent la majorit\xe9 de ces algorithmes massivement d\xe9ploy\xe9s.\nCes algorithmes peuvent faire des pr\xe9dictions sur de nombreux aspects de nos vies: acc\xe8s \xe0 une \xe9cole, prix d'une assurance, publicit\xe9 cibl\xe9e et la reconnaissance faciale en sont quelques exemples. \nIls apprennent \xe0 partir de masse de donn\xe9es toujours plus volumineuse et leur architecture m\xeame (en r\xe9seau) rends leurs pr\xe9dictions difficile \xe0 interpr\xe9ter.\nDe plus en plus de voix s'\xe9l\xe8vent pour demander plus de transparence et de responsabilit\xe9 quant au d\xe9ploiement de tels technologies.\n<br><br>\n<b>Exercice:</b> Continuer votre enqu\xeate sur l'histoire de l'IA en utilisant la chronologie ci-dessous.\nEn cliquant sur un \xe9v\xe8nement, vous acc\xe8derez \xe0 une br\xe8ve description et des illustrations.\n<br><br>\n\nSi vous voulez en apprendre plus, nous vous recommandons l'excellent article <i>La revenche des neurones</i> des sociologues Dominique Cardon, Jean-Philippe Cointet et Antoine Mazi\xe8res.\nCette activit\xe9 est largement inspir\xe9 de leurs travaux.\n");ie.title=e.history.text.title;const re=l('\n<iframe width="100%" height="600" src="https://time.graphics/fr/embed?v=1&id=599729" frameborder="0" allowfullscreen></iframe>\n<div><a  style="font-size: 12px; text-decoration: none;" title="Powered by Time.Graphics" href="https://time.graphics">Powered by Time.Graphics</a></div>\n');re.title=e.history.timeline;const ct=l(b(e.data.video.url,e.data.video.title,e.data.video.width,e.data.video.height));ct.title=e.data.video.title;const ae=l("\n<style>\n.center {\n  display: block;\n  margin-left: auto;\n  margin-right: auto;\n  width: 30%;\n}\n</style>\n<h3> Les \xe9tapes de travail de l'apprentissage machine </h3>\nNous allons maintenant entra\xeener deux algorithmes d'apprentissage automatique diff\xe9rents \xe0 reconna\xeetre des images. \nCe processus se d\xe9composer en 5 \xe9tapes sch\xe9matis\xe9es sur la figure ci-dessous.\n<br>\n<img class=\"center\" size=\"10%\" src=\"https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/assets/images/diagramme_cycle.png\" >\n<br>\nDes probl\xe8mes peuvent appara\xeetre lors de l'une des \xe9tapes.\nPar exemple, les pr\xe9dictions du r\xe9seau de neurone peuvent \xeatre syst\xe9matiquement fausses.\nOn peut alors revenir \xe0 l'une ou l'autre des \xe9tapes pr\xe9c\xe9dentes pour identifier et corriger d'\xe9ventuels probl\xe8mes.\n<h3> Collecte des donn\xe9es </h3>\nDans cette activit\xe9, nous allons collecter les donn\xe9es du probl\xe8me. Vous aurez le choix entre deux bases de donn\xe9es:\n<ol>\n<li> La base de donnn\xe9e <b>miniMASK</b>: elle comporte des images de personnes portant correctement, incorrectement ou pas de masque chirurgical du tout.\nVotre algorithme devra arriver \xe0 diff\xe9rencier ces trois cas de figures.\n<li> La base de donn\xe9e <b>miniROAD</b>: Elle comporte des images prises depuis une voiture. Votre algorithme devra arriver \xe0 diff\xe9rencier trois cas de figures: la voiture peut continuer \xe0 rouler sans danger, la voiture doit s'arr\xeater et la voiture fait f\xe2ce \xe0 un danger imminent.\n</ol>\n<br>\n<b>Exercice:</b> Cliquer sur l'un ou l'autre des boutons ci-dessous pour importer votre base de donn\xe9e pour le reste des activit\xe9s du TP. Vous pourrez toujours refaire le TP plus tard avec l'autre base de donn\xe9e.\n<h3> Donn\xe9es d'entra\xeenement / donn\xe9es de test </h3>\nApr\xe8s avoir choisi vos donn\xe9es, vous pouvez apercevoir qu'elles ont \xe9t\xe9 divis\xe9es en deux ensembles:\n<ul>\n<li> Les <b>donn\xe9es d'entra\xeenement</b>: ce sont les donn\xe9es que votre algorithme d'apprentissate va voir et sur lesquelles il va apprendre.\nPour cela l'algorithme devra avoir les <i>donn\xe9es d'entr\xe9es</i> (les images) et la <i> v\xe9rit\xe9 terrain </i> c'est \xe0 dire les \xe9tiquettes qui ont \xe9t\xe9 apos\xe9 sur les images (par exemple correct, incorrect ou absent pour les donnn\xe9es de masques chirurgicaux).\n<li> Les <b>donn\xe9es de test</b>: Ce sont les donn\xe9es avec lesquelles nous allons \xe9valuer l'algorithme d'apprentissage.\nPuisque notre algorithme n'aura jamais vu ces donn\xe9es, on pourra estimer si l'algo est bien entra\xeen\xe9 lorsqu'il ne fait pas d'erreurs sur les donn\xe9es de test. Pour cela, on va comparer les \xe9tiquettes pr\xe9dites par l'algorithme sur cet ensemble avec les \xe9tiquettes de <i>v\xe9rit\xe9 terrain</i> d\xe9j\xe0 pr\xe9sentes.\n</ul>\n");ae.title=e.data.text.title;const y=Be();y.title=e.data.webcam;const A=q("miniMASK");A.title="Donn\xe9es de ports de masques chirurgicaux";const I=q("miniROAD");I.title="Donn\xe9es de circulation routi\xe8re";const h=Re("localStorage"),c=W("training-set-mlp-vs-knn",h),m=W("test-set-mlp-vs-knn",h),x=H(c);x.title=e.data.browser.train;const w=H(m);w.title=e.data.browser.test;const dt=l(b(e.embedding.video.url,e.embedding.video.title,e.embedding.video.width,e.embedding.video.height));dt.title=e.embedding.video.title;const oe=l("\n<style>\n.center {\n  display: block;\n  margin-left: auto;\n  margin-right: auto;\n  width: 20%;\n}\n</style>\nNous disponsons \xe0 pr\xe9sent d'images brutes, r\xe9partis en deux ensemble: l'ensemble d'<b>entra\xeenement</b> et de <b>test</b>.\nUne images couleur brute peut \xeatre vu comme l'ensemble de troix tableaux de nombres. Chaque tableau repr\xe9sente un canal de couleur: rouge, vert et bleu.\nOn parle des canaux RGB (Red, Green, Blue).\nLes valeurs de ces tableaux repr\xe9sentent l'intensit\xe9 du pixel pour la couleur concern\xe9e.\nL'image finale correspond \xe0 la superposition des troix canaux de couleurs.\nCi-dessous, vous pouvez voir un sch\xe9ma repr\xe9sentant d'une image RGB de 3 par 3 pixels.\n<BR>\n<img class=\"center\" src=\"https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/assets/images/RGB_layers.png\" >\n<BR>\nPuisque nos images sont dans un format carr\xe9 de 224 pixels par 224 pixels, on se retrouve avec 224x224x3 = 150528 valeurs que notre algorithme d'apprentissage doit tra\xeeter.\nLes r\xe9seaux de neurones \xe0 architecture profonde sont capable d'apprendre sur de tels images, mais l'entra\xeenement requiert beaucoup d'images, de temps de calcul et du mat\xe9riel sp\xe9cialis\xe9 (GPU).\n<BR>\n<BR>\nPuisque nos deux algorithmes d'apprentissage vont \xeatre entra\xeen\xe9s dans le navigateur, on se doit de simplifier le probl\xe8me pour \xe9viter de longs calculs. On cherche donc \xe0 extraire des <b>attributs</b> pertinents de l'image.\nPar exemple, on pourrait prendre comme attributs les intensit\xe9s moyennes sur les canaux RGB. On passerait de 150528 valeurs (l'image brute) \xe0 3 valeurs seulement: le taux de rouge, de vert et de bleu.\nC'est une grande simplification et un mod\xe8le pourrait facilement distinguer des objets de couleurs diff\xe9rentes avec tr\xe8s peu de temps d'entra\xeenement.\nCependant, on perdrait l'information sur les formes ou les d\xe9tails de l'image qui ne pourrait pas \xeatre appris par nos algorithmes d'apprentissage.\n<BR>\n<BR>\nAu lieu de cela, nous allons utiliser un r\xe9seau de neurones pr\xe9-entra\xeen\xe9 pour extraire des attributs de l'image.\nOn utilise le r\xe9seau MobileNetV1, qui est un r\xe9seau de neurones convolutionnel qui a \xe9t\xe9 entra\xeen\xe9 sur 1000 cat\xe9gories diff\xe9rentes.\nCe r\xe9seau prends en entr\xe9e une image brute et donne en sortie un vecteur de 1024 attributs abstraits qui ont \xe9t\xe9 pr\xe9alablement appris comme \xe9tant pertinent pour d\xe9crire une image.\nOn appelle ce processus le <b>plongement</b> (embedding en anglais) et nous permet de simplifier des donn\xe9es d'images complexes (150528) en un vecteurs uni-dimensionnel de taille 1024.\nCependant, le \"plongement\" rend d\xe9j\xe0 l'entra\xeenement de nos algorithmes d'apprentissage plus opaque et moins interpr\xe9table.\n<br>\n<br>\n<b>Exercice:</b> Inspecter les attributs de vos images en s\xe9lectionnant une image de l'ensemble d'entra\xeenement ou de test.\nPour vous, ces informations semblent impossible \xe0 interpr\xe9ter mais pour un algorithme de classification, c'est beaucoup plus simple que l'image originale!\n\n");oe.title=e.embedding.text.title;const S=Ue();S.title=e.embedding.title;const j=l("En attente de la s\xe9lection d'une image...<br><br><br><br><br><br><br><br><br><br>");j.title=e.embedding.feature_title;const pt=x.$selected.filter(e=>1===e.length).map(([e])=>c.get(e)).awaitPromises(),mt=w.$selected.filter(e=>1===e.length).map(([e])=>m.get(e)).awaitPromises(),bt=pt.merge(mt);bt.subscribe(e=>{var t=e.x[0].map(function(e){return e=e.toFixed(2)});j.$value.set('<p style="font-size:10px;">'.concat(t.join(", "),"</p>"))}),I.$click.subscribe(async()=>{await C("miniROAD","train"),await C("miniROAD","test")}),A.$click.subscribe(async()=>{await C("miniMASK","train"),await C("miniMASK","test")});const gt=l(b(e.training.video.url,e.training.video.title,e.training.video.width,e.training.video.height));gt.title=e.training.video.title;const $=q("Entra\xeener le kNN");$.title="";const T=q("Entra\xeener le MLP");T.title="";const le=l("\nNous venons de simplifier notre probl\xe8me de reconnaissance d'image en \"plongeant\" nos images brutes dans un espace \xe0 1024 dimensions.\n<BR>\nIl est maintenant temps d'entra\xeener nos algorithmes d'apprentissage. Nous allons entra\xeener deux mod\xe8les diff\xe9rents:\n<ul>\n<li> Un algorithme de <b>k plus proches voisins</b> ou k-Neirest Neighbors (<b>kNN</b>) en anglais.\n<li> Un <b> Perceptron multicouche</b> ou Multi-Laters Perceptron (<b>MLP</b>) en anglais.\n</ul>\nNous allons expliquer bri\xe8vement comment fonctionne ces deux algorithmes, sans entrer dans le d\xe9tail, puis nous entra\xeenerons les deux algorithmes sur notre jeu de donn\xe9es.\n");le.title=e.training.text.title;const ue=l('\nL\'algorithme des k plus proches voisins est un algorithme de classification qui repose sur un principe simple:\n<b>la cat\xe9gorie pr\xe9dite d\'un image sera celle des images voisines.</b>\n<br>\nPour que la notion de voisinage est un sens, il faut encore que l\'on d\xe9finisse <b>une distance</b>.\nOn choisira la distance Euclidienne sur nos images maintenant repr\xe9sent\xe9es par un vecteur de 1024 valeurs.\nLa distance Euclidienne entre deux vecteurs u et v est d\xe9finie comme:<br>\n<img src="https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/assets/images/euclidean_distance.png">\n<br>\n\nLe param\xe8tre <b>k</b> d\xe9fini le nombre d\'images voisines \xe9tiquet\xe9es \xe0 prendre en compte pour \xe9tiqueter une nouvelle image.\nPar exemple, si k=3, une nouvelle image sera \xe9tiquet\xe9e comme l\'\xe9tiquette majoritaire parmi les 3 images \xe9tiquet\xe9es les plus proches selon la distance d.\nPour mieux comprendre, essayez de placer de nouveaux points dans cet espace \xe0 deux dimensions en changeant la valeur de <b>k</b>.\nLes points d\xe9j\xe0 pr\xe9sents peuvent \xeatre assimil\xe9 aux images \xe9tiquet\xe9es de l\'ensemble d\'entra\xeenement et chaque couleur correspond \xe0 une \xe9tiquette diff\xe9rente.\n<br><br>\n<iframe class="center" width="100%" height="500" src="https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/assets/knn/index.html" frameborder="0"></iframe><br>\nCr\xe9dits pour la visualisation int\xe9ractive: St\xe9phanie Stoppel\n<br>\n<b>Exercice:</b> Entra\xeener votre kNN sur votre ensemble d\'entra\xeenement, en choisissant k = 1.\n');ue.title=e.training.knn.text.title;const ce=l("\nLe Perceptron multicouche, Multilayers Perceptron en anglais (MLP), est un type de r\xe9seau de neurones artificiels.\nIl est l'h\xe9ritier du perceptron de Frank Rosenblatt invent\xe9 1957 qui n'avait qu'une seule couche de neurones.\nObservons un sch\xe9ma repr\xe9sentant un neurone artificiel (gauche) et un r\xe9seau de neurones artificiel (droite):\n<br>\n<br>\n<img class=\"center\" size=\"100%\" src=\"https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/assets/images/perceptron.png\" >\n<br>\n\n\xc0 gauche, le neurone artificiel a un comportement inspir\xe9 du neurone biologique: \nil re\xe7oit des signaux d'autres neurones. L'intensit\xe9 des signaux entrants est repr\xe9sent\xe9 par une valeur flottante dans l'ordinateur.\nChaque signal d'entr\xe9e du neurone est pond\xe9r\xe9 par <b>un poids not\xe9 w</b>. Ce sont ces poids que notre r\xe9seau de neurones artificiels va chercher \xe0 apprendre.\nIls peuvent \xeatre <b>positifs ou n\xe9gatifs</b> selon si le signal entrant doit <b>activer ou inhiber</b> le neurone.\n<br><br>\nLe neurone r\xe9alise ensuite une somme (pond\xe9r\xe9 par les poids) de tous les signaux entrants.\nIl renvoie un signal si cette somme pond\xe9r\xe9e est sup\xe9rieur \xe0 un seuil.\nEn r\xe9alit\xe9, ce n'est pas un seuil parfait mais plut\xf4t un seuil liss\xe9.\nCette fonction qui donne la sortie de la valeur de la somme pond\xe9r\xe9e s'appelle une <b>fonction d'activation</b>.\n<br>\n<br>\n\xc0 droite est repr\xe9sent\xe9 un sch\xe9ma o\xf9 les neurones artificiels sont organis\xe9s en couches.\nUn perceptron poss\xe8de une couche d'entr\xe9 (c'est notre vecteur de taille 1024), des couches cach\xe9es et une couche de sortie (ce sont nos trois \xe9tiquettes).\nUn perceptron peut avoir un nombre variable de couches cach\xe9es ainsi qu'un nombre variable de neurones par couche cach\xe9e.\n<br>\nLe perceptron va s'entra\xeener en prenant un paquet d'images d'entra\xeenement, pr\xe9dire leurs \xe9tiquettes et changer les poids du r\xe9seau si la pr\xe9diction est fausse.\nLa taille du paquet d'image est donn\xe9e par le param\xe8tre <b>batchSize</b> tandis que le nombre de fois qu'il va prendre un paquet pour modifier ses poids est donn\xe9 par <b>epochs</b>.\n<br>\n<br>\nNotre perceptron n'a pour le moment qu'une couche cach\xe9e contenant 64 neurones.\n<br><br>\n<b>Exercice:</b> Changer son architecture pour qu'il ait trois couches cach\xe9es comprenant respectivement 128, 64 et 32 neurones puis\nlancer l'entra\xeenement et observer les courbes de co\xfbt (<b>loss</b>) et de pr\xe9cision (<b>accuracy</b>).\n<br><br>\nLa courbe de co\xfbt (loss) doit d\xe9croitre car elle repr\xe9sente l'erreur qui est minimis\xe9 au fur et \xe0 mesure des it\xe9rations. \nLa courbe de pr\xe9cision (accuracy) doit augmenter car elle repr\xe9sente le nombre de bonne r\xe9ponse de votre perceptron.\nCependant, ces courbes sont calcul\xe9s sur l'ensemble d'entra\xeenement, le m\xeame avec lequel vous avez entra\xeen\xe9 le mod\xe8le.\nDans la prochaine activit\xe9, nous allons nous assurer que les deux mod\xe8les (kNN et le MLP) g\xe9n\xe9ralisent bien sur de nouvelles donnn\xe9es en les \xe9valuant sur les donn\xe9es des <b>test</b>.\n");ce.title=e.training.mlp.text.title;const g=Oe({k:1,dataStore:h}).sync("mlp-vs-knn-knn"),de=Y(g);de.title=e.training.knn.params;const pe=Z(g);pe.title=e.training.knn.progress;const f=Ve({layers:[64],epochs:20,dataStore:h}).sync("mlp-vs-knn-mlp"),me=Y(f);me.title=e.training.mlp.params;const be=Z(f);be.title=e.training.mlp.progress;const he=Ke(f,["loss","accuracy"]);he.title=e.training.mlp.plot,$.$click.subscribe(()=>{g.train(c,"features")}),T.$click.subscribe(()=>{f.train(c,"features")});const vt=l(b(e.evaluation.video.url,e.evaluation.video.title,e.evaluation.video.width,e.evaluation.video.height));vt.title=e.evaluation.video.title;const ge=l("\n\xc0 pr\xe9sent que nos deux mod\xe8les d'apprentissage sont entra\xeen\xe9s, nous allons \xe9valuer leurs performances sur l'<b>ensemble de tests</b>.\nL'ensemble de test contient des images que le mod\xe8le n'a pas encore vu.\n<br>\nNous allons utilis\xe9 deux mesures pour \xe9valuer nos mod\xe8les: \n<ul>\n<li> La <b>mesure de pr\xe9cision globale</b> (global accuracy), qui se calcule comme le nombre de bonnes pr\xe9dictions sur l'ensemble divis\xe9 par la taille de l'ensemble.\n<li> La <b>matrice de confusion</b> qui est un tableau dont les lignes sont les cat\xe9gories r\xe9elle (que doit pr\xe9dire le classifieur) et les colonnes sont les cat\xe9gories estim\xe9es (qu'a effectivement pr\xe9dit le classifieur).\nUn classifieur est bon sur l'ensemble test\xe9 si les valeurs de la matrice de corr\xe9lation se concentrent sur la diagonale: les cat\xe9gories que doit pr\xe9dire le classifieur sont effectiement celles pr\xe9dites.\n</ul>\n<br>\nAppliquons ces outils d'\xe9valuation sur nos deux classifieurs (kNN et MLP) et nos deux ensembles (entra\xeenement et test).\n<br>\n<br>\n<b>Exercice:</b> Mettre \xe0 jours les pr\xe9dictions (pr\xe9cisions et matrices confusions) sur les mod\xe8les et les ensembles.\n<br><br>\nPour interpr\xe9ter ces r\xe9sultats, on peut distinguer quatres situations:\n<ol>\n<li> Le mod\xe8le a une bonne pr\xe9cision sur l'ensemble d'entra\xeenement et l'ensemble de test.\nC'est ce que l'on cherche \xe0 avoir et qui permet de dire que le classifieur sait g\xe9n\xe9raliser ce qu'il a appris sur de nouvelles donn\xe9es.\n<li> Le mod\xe8le n'a pas une bonne pr\xe9cision ni sur l'ensemble d'entra\xeenement ni sur l'ensemble de test.\nDans ce cas, on dit que le mod\xe8le a <b>sous-appris</b> ou qu'il n'a pas appris tout court.\n<li> Le mod\xe8le a une bonne pr\xe9cision sur l'ensemble d'entra\xeenement mais pas l'ensemble de test. \nOn dit que le mod\xe8le a <b>sur-appris</b>. Le mod\xe8le sait reconna\xeetre les images qu'il a d\xe9j\xe0 vu mais ne sait pas g\xe9n\xe9raliser avec de nouvelles images.\n<li> Le mod\xe8le a une bonne pr\xe9cision sur l'ensemble de test mais pas l'ensemble d'entra\xeenement.\nCette situation n'arrive quasiment jamais en pratique.\n</ol>\n<br>\n<b>Exercice:</b> Lequel de vos mod\xe8le (kNN ou MLP) est le plus performant? Est-ce qu'un mod\xe8le a sur-appris ou sous-appris?<br>\n<br>\nDans la pratique, il faudrait retourner aux \xe9tapes pr\xe9c\xe9dentes depuis la collecte de donn\xe9es pour essayer d'augmenter la pr\xe9cision de vos mod\xe8les si celle-ci est mauvaise. \n");ge.title=e.evaluation.text.title;const D=_({name:"MLP_train",dataset:c,dataStore:h}),B=_({name:"KNN_train",dataset:c,dataStore:h}),R=_({name:"MLP_test",dataset:m,dataStore:h}),U=_({name:"KNN_test",dataset:m,dataStore:h}),O=q(e.evaluation.knn.button.content);O.title=e.evaluation.knn.button.title;const V=q(e.evaluation.mlp.button.content);V.title=e.evaluation.mlp.button.title;const ve=M(D);ve.title=e.evaluation.mlp.matrix.train;const fe=M(B);fe.title=e.evaluation.knn.matrix.train;const xe=M(R);xe.title=e.evaluation.mlp.matrix.test;const we=M(U);we.title=e.evaluation.knn.matrix.test,O.$click.subscribe(async()=>{g.ready||X(new Error("Le classifieur kNN n'a pas \xe9t\xe9 entra\xeen\xe9 sur les donn\xe9es d'entra\xeenement")),await B.clear(),await U.clear(),await B.predict(g,c),await U.predict(g,m)}),V.$click.subscribe(async()=>{g.ready||X(new Error("Le classifieur MLP n'a pas \xe9t\xe9 entra\xeen\xe9 sur les donn\xe9es d'entra\xeenement")),
await D.clear(),await R.clear(),await D.predict(f,c),await R.predict(f,m)});const ft=l(b(e.deployment.video.url,e.deployment.video.title,e.deployment.video.width,e.deployment.video.height));ft.title=e.deployment.video.title;const qe=l("\nMaintenant que nous avons deux mod\xe8les d'apprentissage entra\xeen\xe9s, on peut inspecter quelles sont les situatios o\xf9 nos mod\xe8les \xe9chouent.\n<br>\n<br>\n<b>Exercice:</b><br>\nSi vous ne disposez pas d'une cam\xe9ra, vous pouvez s\xe9lectionner les images des ensembles d'entra\xeenement ou de test afin de visualiser leurs pr\xe9dictions.\n<br>\nSi vous disposez d'une webcam, vous pouvez filmer votre environement pour tester votre algorithme. Vous devez auparavant activer votre cam\xe9ra.\n<br>\n<br>\nSelon l'application que vous avez choisi, les masques chirurgicaux resp. la conduite autonome, on pourrait imaginer que le d\xe9ploiement de nos mod\xe8le d'apprentissage se fasse avec une cam\xe9ra plac\xe9e \xe0 l'entr\xe9e d'une gare resp. dans l'habitacle d'une voiture.\n<br>\n<br>\n<b>Exercice:</b> Imaginez des situations o\xf9 une erreur de votre algorithme pourrait avoir de grandes r\xe9percussions humaines.\n<br>\n<br>\nLes param\xe8tres de votre algorithme entra\xeen\xe9 peuvent \xeatre enregistr\xe9.\nEn particulier, nous sommes int\xe9ress\xe9s d'enregistr\xe9 les param\xe8tres du perceptron multicouche pour la suite de ce TP. <br><br>\n<b>Exercice:</b> Allez dans les param\xe8tres en cliquant sur l'ic\xf4ne <img size=\"5%\" src=\"https://www.lisn.upsaclay.fr/~tsanchez/TP_IA/assets/images/settings.png\" > puis cliquer sur \"Download Model\" pour t\xe9l\xe9charger les param\xe8tres du perceptron (MLP) entra\xeen\xe9.\nVous aurez deux fichiers \xe0 t\xe9l\xe9charger: un fichier .json (comprenant l'architecture du perceptron) et un fichier .bin (contenant les poids des connnexions entre les neurones).\n<b>\n");qe.title=e.evaluation.text.title;const xt=y.$images.filter(()=>y.$active.value).map(async e=>S.process(e)).awaitPromises(),wt=x.$selected.filter(e=>1===e.length).map(([e])=>c.get(e)).awaitPromises().map(e=>e.x),qt=w.$selected.filter(e=>1===e.length).map(([e])=>m.get(e)).awaitPromises().map(e=>e.x),ye=qt.merge(wt).merge(xt),yt=y.$images.filter(()=>y.$active.value),Pt=x.$selected.filter(e=>1===e.length).map(([e])=>c.get(e)).awaitPromises().map(e=>e.image),Lt=w.$selected.filter(e=>1===e.length).map(([e])=>m.get(e)).awaitPromises().map(e=>e.image),_t=yt.map(async e=>Nt(e)).awaitPromises(),Mt=_t.merge(Pt).merge(Lt),Pe=Je(Mt);Pe.title=e.deployment.display;const kt=ye.map(async e=>f.predict(e)).awaitPromises(),St=ye.map(async e=>g.predict(e)).awaitPromises(),Le=ee(kt);Le.title=e.deployment.mlp.plot;const Ne=ee(St);Ne.title=e.deployment.knn.plot;const Ct=l(b(e.adversarial.video.url,e.adversarial.video.title,e.adversarial.video.width,e.adversarial.video.height));Ct.title=e.adversarial.video.title;const Et=l("\nAttaque adversaire, hacking ... ");Et.title=e.adversarial.text.title;const _e=l("\nCe travail pratique a \xe9t\xe9 \xe9crit et d\xe9velopp\xe9 par:\n<ul>\n<li> <a href=\"https://www.lisn.upsaclay.fr/~tsanchez/\">T\xe9o Sanchez</a>, doctorant et enseignant \xe0 l'Universit\xe9 Paris-Saclay. Ses recherches s'int\xe9ressent \xe0 la vulgarisation des algorithmes d'apprentissage au moyen d'outils int\xe9ractifs.\n<li> Pablo Sanchez, enseignant de Science de l'Ing\xe9nieur au lyc\xe9e Jean-Baptiste Say.\n</ul>\n\nL'application a \xe9t\xe9 r\xe9alis\xe9 avec <a href=\"https://marcelle.dev/\">Marcelle</a>, une bo\xeete \xe0 outils modulaire et open source pour la programmation d'applications interactives d'apprentissage automatique.\nMarcelle a \xe9t\xe9 d\xe9velopp\xe9e par:\n<ul>\n<li> <a href=\"https://www.julesfrancoise.com/\">Jules Fran\xe7ois</a>e, chercheur CNRS au LISN, Universit\xe9 Paris-Saclay\n<li> <a href=\"https://baptistecaramiaux.com/\">Baptiste Cararmiaux</a>, chercheur CNRS \xe0 l'ISIR, Sorbonne Universit\xe9\n</ul>\n");_e.title=e.credits.text.title;const zt=l(b(e.research.video.url,e.research.video.title,e.research.video.width,e.research.video.height));zt.title=e.research.video.title;const Me=l("\nNous vous serions tr\xe8s reconnaissant de r\xe9pondre \xe0 ce questionnaire anonyme<a>.\n<br>\n<br>\nLes r\xe9ponses serviront la recherche publique \xe0 comprendre ce que vous avez appris et ce que vous pensez du domaine de l'intelligence artificielle.\nLes donn\xe9es sont anonymes et stock\xe9s sur un serveur \xe0 l'universit\xe9 fran\xe7aise (Universit\xe9 Paris-Saclay). De plus, l'\xe9tude a \xe9t\xe9 approuv\xe9e par un comit\xe9 \xe9thique de recherche en charge de veiller \xe0 la bonne protection, l'utilisation et la confidentialit\xe9 des donn\xe9es collect\xe9es.");Me.title=e.research.text.title;const p=Ge({title:e.misc.dashboards.title,author:e.misc.author.name});p.page(e.introduction.name).sidebar().use(ne),p.page(e.history.name).sidebar().use("Consignes",ie,"Outils",re),p.page(e.data.name).sidebar().use("Consignes",ae,"Outils",[A,I],[x,w]),p.page(e.embedding.name).sidebar(S).use("Consignes",oe,"Outils",j,[x,w]),p.page(e.training.name).sidebar().use("Consignes",le,"k plus proches voisins (kNN)",ue,[de,$,pe],"Perceptron multicouche (MLP)",ce,[me,T,be],he),p.page(e.evaluation.name).sidebar().use("Consignes",ge,"Outils",[O,V],[fe,ve],[we,xe]),p.page(e.deployment.name).sidebar(y).use("Consignes",qe,"Outils",[x,w],"Pr\xe9dictions",[Pe,Ne,Le]),p.page(e.research.name).sidebar().use(Me),p.page(e.credits.name).use(_e),p.settings.dataStores(h).datasets(c).models(g,f),p.show();